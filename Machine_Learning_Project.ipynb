{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "wSM8Ky3xfGcv",
        "outputId": "34112399-67ae-47a1-919a-ad2d7fa8cf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all seasons befor dropna: (1140, 26)\n",
            "Data loaded and processed. Total shape: (1140, 27)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Date   Time        HomeTeam          AwayTeam FTR  FTHG  \\\n",
              "0  2019-08-09 00:00:00  20:00       Liverpool           Norwich   H     4   \n",
              "1  2019-08-10 00:00:00  12:30        West Ham          Man City   A     0   \n",
              "2  2019-08-10 00:00:00  15:00     Bournemouth  Sheffield United   D     1   \n",
              "3  2019-08-10 00:00:00  15:00         Burnley       Southampton   H     3   \n",
              "4  2019-08-10 00:00:00  15:00  Crystal Palace           Everton   D     0   \n",
              "5  2019-08-10 00:00:00  15:00         Watford          Brighton   A     0   \n",
              "6  2019-08-10 00:00:00  17:30       Tottenham       Aston Villa   H     3   \n",
              "7  2019-08-11 00:00:00  14:00       Leicester            Wolves   D     0   \n",
              "8  2019-08-11 00:00:00  14:00       Newcastle           Arsenal   A     0   \n",
              "9  2019-08-11 00:00:00  16:30      Man United           Chelsea   H     4   \n",
              "\n",
              "   FTAG  HS  AS  HST  ...  HR  AR  Start_Temp_C  Start_Wind_kmh  \\\n",
              "0     1  15  12    7  ...   0   0         18.60           27.72   \n",
              "1     5   5  14    3  ...   0   0         21.39           37.08   \n",
              "2     1  13   8    3  ...   0   0         19.14           46.44   \n",
              "3     0  10  11    4  ...   0   0         16.33           25.38   \n",
              "4     0   6  10    2  ...   0   1         20.94           44.28   \n",
              "5     3  11   5    3  ...   0   0         20.96           40.68   \n",
              "6     1  31   7    7  ...   0   0         20.54           31.68   \n",
              "7     0  15   8    1  ...   0   0         17.62           18.11   \n",
              "8     1   9   8    2  ...   0   0         14.03           11.16   \n",
              "9     0  11  18    5  ...   0   0         16.30           22.32   \n",
              "\n",
              "   Start_Wind_Degree  Start_Humidity  Start_Precip_mm  Start_Conditions  \\\n",
              "0                180              77             0.00  scattered clouds   \n",
              "1                230              63             0.00     broken clouds   \n",
              "2                250              74             0.00     broken clouds   \n",
              "3                236              96             2.29     moderate rain   \n",
              "4                230              65             0.00  scattered clouds   \n",
              "5                230              66             0.00  scattered clouds   \n",
              "6                220              63             0.00     broken clouds   \n",
              "7                260              69             0.00   overcast clouds   \n",
              "8                 40              99             0.82        light rain   \n",
              "9                270              77             0.00     broken clouds   \n",
              "\n",
              "                 End_Conditions  match_id  \n",
              "0               overcast clouds         0  \n",
              "1                 broken clouds         1  \n",
              "2              scattered clouds         2  \n",
              "3                 moderate rain         3  \n",
              "4              scattered clouds         4  \n",
              "5                 broken clouds         5  \n",
              "6                    few clouds         6  \n",
              "7                 broken clouds         7  \n",
              "8  light intensity drizzle rain         8  \n",
              "9                   shower rain         9  \n",
              "\n",
              "[10 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae75f866-9a87-4241-ab17-cb748a7d7228\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTR</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HST</th>\n",
              "      <th>...</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>Start_Temp_C</th>\n",
              "      <th>Start_Wind_kmh</th>\n",
              "      <th>Start_Wind_Degree</th>\n",
              "      <th>Start_Humidity</th>\n",
              "      <th>Start_Precip_mm</th>\n",
              "      <th>Start_Conditions</th>\n",
              "      <th>End_Conditions</th>\n",
              "      <th>match_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-08-09 00:00:00</td>\n",
              "      <td>20:00</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>Norwich</td>\n",
              "      <td>H</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.60</td>\n",
              "      <td>27.72</td>\n",
              "      <td>180</td>\n",
              "      <td>77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>12:30</td>\n",
              "      <td>West Ham</td>\n",
              "      <td>Man City</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.39</td>\n",
              "      <td>37.08</td>\n",
              "      <td>230</td>\n",
              "      <td>63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>15:00</td>\n",
              "      <td>Bournemouth</td>\n",
              "      <td>Sheffield United</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.14</td>\n",
              "      <td>46.44</td>\n",
              "      <td>250</td>\n",
              "      <td>74</td>\n",
              "      <td>0.00</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>15:00</td>\n",
              "      <td>Burnley</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.33</td>\n",
              "      <td>25.38</td>\n",
              "      <td>236</td>\n",
              "      <td>96</td>\n",
              "      <td>2.29</td>\n",
              "      <td>moderate rain</td>\n",
              "      <td>moderate rain</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>15:00</td>\n",
              "      <td>Crystal Palace</td>\n",
              "      <td>Everton</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.94</td>\n",
              "      <td>44.28</td>\n",
              "      <td>230</td>\n",
              "      <td>65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>15:00</td>\n",
              "      <td>Watford</td>\n",
              "      <td>Brighton</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.96</td>\n",
              "      <td>40.68</td>\n",
              "      <td>230</td>\n",
              "      <td>66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2019-08-10 00:00:00</td>\n",
              "      <td>17:30</td>\n",
              "      <td>Tottenham</td>\n",
              "      <td>Aston Villa</td>\n",
              "      <td>H</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.54</td>\n",
              "      <td>31.68</td>\n",
              "      <td>220</td>\n",
              "      <td>63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>few clouds</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2019-08-11 00:00:00</td>\n",
              "      <td>14:00</td>\n",
              "      <td>Leicester</td>\n",
              "      <td>Wolves</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17.62</td>\n",
              "      <td>18.11</td>\n",
              "      <td>260</td>\n",
              "      <td>69</td>\n",
              "      <td>0.00</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2019-08-11 00:00:00</td>\n",
              "      <td>14:00</td>\n",
              "      <td>Newcastle</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14.03</td>\n",
              "      <td>11.16</td>\n",
              "      <td>40</td>\n",
              "      <td>99</td>\n",
              "      <td>0.82</td>\n",
              "      <td>light rain</td>\n",
              "      <td>light intensity drizzle rain</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2019-08-11 00:00:00</td>\n",
              "      <td>16:30</td>\n",
              "      <td>Man United</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>H</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.30</td>\n",
              "      <td>22.32</td>\n",
              "      <td>270</td>\n",
              "      <td>77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>shower rain</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae75f866-9a87-4241-ab17-cb748a7d7228')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae75f866-9a87-4241-ab17-cb748a7d7228 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae75f866-9a87-4241-ab17-cb748a7d7228');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e700905a-b078-4c6c-a474-f4f81eb9412b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e700905a-b078-4c6c-a474-f4f81eb9412b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e700905a-b078-4c6c-a474-f4f81eb9412b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_seasons_df"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# --- 1. LOAD DATA (CONSOLIDATED) ---\n",
        "\n",
        "# Paths to your files\n",
        "path_prefix = '/content/drive/MyDrive/archive-2/Data_with_90_minutes/'\n",
        "file_paths = {\n",
        "    '19-20': '2019-20_weather_90_full.csv',\n",
        "    '20-21': '2020-21_weather_90.csv',\n",
        "    '21-22': '2021-22_weather_90.csv',\n",
        "}\n",
        "\n",
        "# Columns we need\n",
        "columns_req = [\n",
        "    'Date', 'Time',\n",
        "    'HomeTeam', 'AwayTeam', 'FTR',\n",
        "    'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST',\n",
        "    'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR',\n",
        "    'Start_Temp_C', 'Start_Wind_kmh', 'Start_Wind_Degree',\n",
        "    'Start_Humidity', 'Start_Precip_mm', 'Start_Conditions', 'End_Conditions'\n",
        "]\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "# Load and prepare all CSVs\n",
        "for key, file_path in file_paths.items():\n",
        "    try:\n",
        "        df = pd.read_csv(f\"{path_prefix}{file_path}\")\n",
        "        df = df[columns_req]\n",
        "\n",
        "        # Correct/unify date format\n",
        "        df.loc[:,'Date'] = pd.to_datetime(df['Date'], #format='%d/%m/%y',\n",
        "                                          errors='coerce', dayfirst=True)\n",
        "\n",
        "        data_frames.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "# --- 2. CREATE SINGLE MASTER DATAFRAME ---\n",
        "\n",
        "all_seasons_df = pd.concat(data_frames, ignore_index=True)\n",
        "print(f'all seasons befor dropna: {all_seasons_df.shape}')\n",
        "all_seasons_df = all_seasons_df.dropna(subset=['Date']) # Remove rows with invalid dates\n",
        "all_seasons_df = all_seasons_df.sort_values(by='Date').reset_index(drop=True)\n",
        "all_seasons_df['match_id'] = all_seasons_df.index\n",
        "\n",
        "\n",
        "print(f\"Data loaded and processed. Total shape: {all_seasons_df.shape}\")\n",
        "all_seasons_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjz9w9Je7IEJ"
      },
      "source": [
        "# One-hot encoding for weather data. Has to be changed to new csv with 90 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0mfRC5s6kL",
        "outputId": "07aedb2b-790d-48f4-deca-8c3fc8962e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting weather processing for the current DataFrame...\n",
            "\n",
            "--- Processing column: 'Start_Conditions' ---\n",
            "Distribution of weather categories for Start_Conditions:\n",
            "Start_Conditions_Category\n",
            "cloudy           585\n",
            "rain             234\n",
            "clear_sky        208\n",
            "moderate_rain     69\n",
            "fog               34\n",
            "snow               6\n",
            "heavy_rain         3\n",
            "thunderstorm       1\n",
            "Name: count, dtype: int64\n",
            "Applying One-Hot Encoding for Start_Conditions...\n",
            "Done! Created 8 new numeric columns for Start_Conditions.\n",
            "\n",
            "--- Processing column: 'End_Conditions' ---\n",
            "Distribution of weather categories for End_Conditions:\n",
            "End_Conditions_Category\n",
            "cloudy           574\n",
            "rain             234\n",
            "clear_sky        219\n",
            "moderate_rain     72\n",
            "fog               30\n",
            "heavy_rain         7\n",
            "snow               4\n",
            "Name: count, dtype: int64\n",
            "Applying One-Hot Encoding for End_Conditions...\n",
            "Done! Created 7 new numeric columns for End_Conditions.\n",
            "\n",
            "------------------------------------------------\n",
            "Total columns after processing: 40\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_work = all_seasons_df.copy()\n",
        "\n",
        "print(\"Starting weather processing for the current DataFrame...\")\n",
        "\n",
        "# 1. Classification Function\n",
        "def map_weather_description(description):\n",
        "    \"\"\"\n",
        "    Maps weather descriptions to a main category based on severity.\n",
        "    Order: Dangerous -> Precipitation -> Visibility -> Clouds -> Clear\n",
        "    \"\"\"\n",
        "    if pd.isna(description):\n",
        "        return 'Unknown'\n",
        "\n",
        "    # Convert to lowercase for easier comparison\n",
        "    desc = str(description).lower()\n",
        "\n",
        "    # 1. Thunderstorm (Highest Priority)\n",
        "    if 'thunderstorm' in desc:\n",
        "        return 'thunderstorm'\n",
        "\n",
        "    # 2. Snow and Ice\n",
        "    if 'snow' in desc or 'sleet' in desc or 'freezing' in desc:\n",
        "        return 'snow'\n",
        "\n",
        "    # 3. Heavy Rain\n",
        "    if 'heavy' in desc or 'extreme' in desc or 'ragged' in desc:\n",
        "        return 'heavy_rain'\n",
        "\n",
        "    # 4. Moderate Rain / Showers\n",
        "    if 'moderate' in desc or 'shower' in desc:\n",
        "        return 'moderate_rain'\n",
        "\n",
        "    # 5. Light Rain / Drizzle\n",
        "    if 'rain' in desc or 'drizzle' in desc:\n",
        "        return 'rain'\n",
        "\n",
        "    # 6. Visibility (Fog/Mist)\n",
        "    if 'mist' in desc or 'fog' in desc or 'haze' in desc:\n",
        "        return 'fog'\n",
        "\n",
        "    # 7. Clouds\n",
        "    if 'clouds' in desc:\n",
        "        return 'cloudy'\n",
        "\n",
        "    # 8. Clear Sky\n",
        "    if 'clear' in desc or 'sun' in desc:\n",
        "        return 'clear_sky'\n",
        "\n",
        "    # Fallback\n",
        "    return 'Other'\n",
        "\n",
        "# 2. Define the columns you want to process\n",
        "target_columns = ['Start_Conditions', 'End_Conditions']\n",
        "\n",
        "for col_name in target_columns:\n",
        "    if col_name in df_work.columns:\n",
        "        print(f\"\\n--- Processing column: '{col_name}' ---\")\n",
        "\n",
        "        # A) Categorize\n",
        "        temp_cat_col = f'{col_name}_Category'\n",
        "        df_work[temp_cat_col] = df_work[col_name].apply(map_weather_description)\n",
        "\n",
        "        print(f\"Distribution of weather categories for {col_name}:\")\n",
        "        print(df_work[temp_cat_col].value_counts())\n",
        "\n",
        "        # B) One-Hot Encoding\n",
        "        print(f\"Applying One-Hot Encoding for {col_name}...\")\n",
        "        weather_features = pd.get_dummies(df_work[temp_cat_col], prefix=col_name, dtype=int)\n",
        "\n",
        "        # C) Concatenate\n",
        "        df_work = pd.concat([df_work, weather_features], axis=1)\n",
        "\n",
        "        # D) Cleanup\n",
        "        # Remove the original text column and the temporary category column\n",
        "        df_work.drop([col_name, temp_cat_col], axis=1, inplace=True)\n",
        "\n",
        "        print(f\"Done! Created {weather_features.shape[1]} new numeric columns for {col_name}.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\nWARNING: Column '{col_name}' not found in DataFrame!\")\n",
        "        print(\"Available columns:\", df_work.columns.tolist())\n",
        "\n",
        "# Final check\n",
        "print(\"\\n------------------------------------------------\")\n",
        "print(\"Total columns after processing:\", len(df_work.columns))\n",
        "print(\"Finished.\")\n",
        "\n",
        "playing_stat = df_work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt5Toyq3fyNN"
      },
      "source": [
        "# Feature-Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4HIVXytifmop"
      },
      "outputs": [],
      "source": [
        "def classify_kickoff_time(df):\n",
        "    \"\"\"\n",
        "    Classifies the kickoff time ('Time') into Afternoon (0) or Evening (1).\n",
        "    Creates the 'TMKO' column.\n",
        "\n",
        "    Logic:\n",
        "    - 0 (Afternoon): Kickoff before 5 PM (17:00)\n",
        "    - 1 (Evening): Kickoff at 5 PM (17:00) or later\n",
        "    \"\"\"\n",
        "\n",
        "    df_out = df.copy()\n",
        "\n",
        "    # --- STEP 0: Clean columns to prevent _x/_y suffixes ---\n",
        "    # Find all columns starting with TMKO (TMKO, TMKO_x, TMKO_y)\n",
        "    cols_to_drop = [col for col in df_out.columns if col.startswith('TMKO')]\n",
        "    if cols_to_drop:\n",
        "        df_out = df_out.drop(columns=cols_to_drop)\n",
        "\n",
        "    # --- STEP 1: Extract hour ---\n",
        "    # Ensures the 'Time' column is treated as datetime\n",
        "    # and extracts the hour as a number (e.g., \"16:30\" -> 16)\n",
        "    try:\n",
        "        # Fill missing times (NaN) with '00:00' before conversion\n",
        "        hour = pd.to_datetime(df_out['Time'].fillna('00:00'), format='%H:%M').dt.hour\n",
        "    except ValueError as e:\n",
        "        print(f\"Error converting the 'Time' column: {e}\")\n",
        "        print(\"Ensure all times are in 'HH:MM' format (e.g., 16:30).\")\n",
        "        # Show a few problematic values\n",
        "        print(\"Problem data (examples):\")\n",
        "        print(df_out[pd.to_datetime(df_out['Time'], format='%H:%M', errors='coerce').isna()]['Time'].head())\n",
        "        return df # Return original DF if an error occurs\n",
        "\n",
        "    # --- STEP 2: Classify ---\n",
        "    df_out['TMKO'] = np.where(hour >= 17, 1, 0)\n",
        "\n",
        "    return df_out\n",
        "\n",
        "def get_strict_rolling_avg(df, stats_map, window_size=3):\n",
        "    \"\"\"\n",
        "    Calculates the rolling average of the LAST 'window_size' matches.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Create a \"long\" version of the data\n",
        "    generic_cols = list(stats_map.keys())\n",
        "    home_df = df[['match_id', 'Date', 'HomeTeam'] + generic_cols].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "\n",
        "    away_cols = list(stats_map.values())\n",
        "    away_df = df[['match_id', 'Date', 'AwayTeam'] + away_cols].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_rename_map = dict(zip(away_cols, generic_cols))\n",
        "    away_df.rename(columns=away_rename_map, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "\n",
        "    # 2. Combine and sort by date\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3. Calculate and assign rolling average\n",
        "    df_out = df.copy()\n",
        "\n",
        "    # Prepare temporary DataFrames for home/away merges\n",
        "    home_merge_df = all_stats_df[all_stats_df['is_home_match'] == 1][['match_id', 'Team']].copy()\n",
        "    home_merge_df.rename(columns={'Team': 'HomeTeam'}, inplace=True)\n",
        "    away_merge_df = all_stats_df[all_stats_df['is_home_match'] == 0][['match_id', 'Team']].copy()\n",
        "    away_merge_df.rename(columns={'Team': 'AwayTeam'}, inplace=True)\n",
        "\n",
        "    for home_stat, away_stat in stats_map.items():\n",
        "        # 1. Calculate rolling avg (includes current match)\n",
        "        rolling_avg_series = all_stats_df.groupby('Team')[home_stat].rolling(window=window_size).mean()\n",
        "        rolling_avg_series = rolling_avg_series.reset_index(level=0, drop=True)\n",
        "\n",
        "        # 2. Assign average as a *temporary* column\n",
        "        all_stats_df['TEMP_AVG'] = rolling_avg_series\n",
        "\n",
        "        # 3. Get the average value from the PREVIOUS row (.shift(1))\n",
        "        all_stats_df['PREV_AVG'] = all_stats_df.groupby('Team')['TEMP_AVG'].shift(1)\n",
        "\n",
        "        # --- 4. Merge back to \"wide\" format ---\n",
        "\n",
        "        # Get home team data and rename column (e.g., 'AHST')\n",
        "        home_data = all_stats_df[all_stats_df['is_home_match'] == 1][['match_id', 'PREV_AVG']]\n",
        "        home_data = home_data.rename(columns={'PREV_AVG': f'A{home_stat}'})\n",
        "        home_merge_df = home_merge_df.merge(home_data, on='match_id', how='left')\n",
        "\n",
        "        # Get away team data and rename column (e.g., 'AAST')\n",
        "        away_data = all_stats_df[all_stats_df['is_home_match'] == 0][['match_id', 'PREV_AVG']]\n",
        "        away_data = away_data.rename(columns={'PREV_AVG': f'A{away_stat}'})\n",
        "        away_merge_df = away_merge_df.merge(away_data, on='match_id', how='left')\n",
        "\n",
        "    # --- 5. Final Merges ---\n",
        "    df_out = df_out.merge(home_merge_df, on=['match_id', 'HomeTeam'], how='left')\n",
        "    df_out = df_out.merge(away_merge_df, on=['match_id', 'AwayTeam'], how='left')\n",
        "\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def get_previous_game_form(df):\n",
        "    \"\"\"\n",
        "    Determines the result (Won/NotWin) of each team's last match.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Calculate result (Form) for each match from the team's perspective\n",
        "\n",
        "    # --- Home Data ---\n",
        "    home_df = df[['match_id', 'Date', 'HomeTeam', 'FTR']].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "    home_df['Won'] = (home_df['FTR'] == 'H').astype(int)\n",
        "    home_df['NotWin'] = (home_df['FTR'] != 'H').astype(int)\n",
        "\n",
        "    # --- Away Data ---\n",
        "    away_df = df[['match_id', 'Date', 'AwayTeam', 'FTR']].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "    away_df['Won'] = (away_df['FTR'] == 'A').astype(int)\n",
        "    away_df['NotWin'] = (away_df['FTR'] != 'A').astype(int)\n",
        "\n",
        "    # 2. Combine and sort by date\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3. Create \"Previous\" form for each team\n",
        "    all_stats_df['P_Won'] = all_stats_df.groupby('Team')['Won'].shift(1)\n",
        "    all_stats_df['P_NotWin'] = all_stats_df.groupby('Team')['NotWin'].shift(1)\n",
        "\n",
        "    # 4. Merge back to \"wide\" format\n",
        "    df_out = df.copy()\n",
        "\n",
        "    # Home teams\n",
        "    home_prev_data = all_stats_df[all_stats_df['is_home_match'] == 1].copy()\n",
        "    home_prev_data.rename(columns={'Team': 'HomeTeam', 'P_Won': 'PHFR_Won', 'P_NotWin': 'PHFR_NotWin'}, inplace=True)\n",
        "    cols_to_merge_home = ['match_id', 'HomeTeam', 'PHFR_Won', 'PHFR_NotWin']\n",
        "    df_out = df_out.merge(home_prev_data[cols_to_merge_home], on=['match_id', 'HomeTeam'], how='left')\n",
        "\n",
        "    # Away teams\n",
        "    away_prev_data = all_stats_df[all_stats_df['is_home_match'] == 0].copy()\n",
        "    away_prev_data.rename(columns={'Team': 'AwayTeam', 'P_Won': 'PAFR_Won', 'P_NotWin': 'PAFR_NotWin'}, inplace=True)\n",
        "    cols_to_merge_away = ['match_id', 'AwayTeam', 'PAFR_Won', 'PAFR_NotWin']\n",
        "    df_out = df_out.merge(away_prev_data[cols_to_merge_away], on=['match_id', 'AwayTeam'], how='left')\n",
        "\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def get_last_match_overall(df, stats_map):\n",
        "    \"\"\"\n",
        "    Gets the stats of the last match for each team,\n",
        "    regardless of venue (Home or Away).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Create a \"long\" version of the data\n",
        "    generic_cols = list(stats_map.keys())\n",
        "    home_df = df[['match_id', 'Date', 'HomeTeam'] + generic_cols].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "\n",
        "    away_cols = list(stats_map.values())\n",
        "    away_df = df[['match_id', 'Date', 'AwayTeam'] + away_cols].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_rename_map = dict(zip(away_cols, generic_cols))\n",
        "    away_df.rename(columns=away_rename_map, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "\n",
        "    # 2. Combine and sort by date\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3. Create \"Previous\" stats for each team\n",
        "    prev_cols = {}\n",
        "    for col in generic_cols:\n",
        "        prev_cols[f'P_{col}'] = all_stats_df.groupby('Team')[col].shift(1)\n",
        "\n",
        "    prev_stats_df = pd.DataFrame(prev_cols)\n",
        "    all_stats_df = pd.concat([all_stats_df, prev_stats_df], axis=1)\n",
        "\n",
        "    # 4. Merge back to \"wide\" format\n",
        "    df_out = df.copy()\n",
        "\n",
        "    # --- Merge for Home teams ---\n",
        "    home_prev_data = all_stats_df[all_stats_df['is_home_match'] == 1].copy()\n",
        "    home_prev_data.rename(columns={'Team': 'HomeTeam'}, inplace=True)\n",
        "    # Rename columns: 'P_HST' -> 'PHST'\n",
        "    home_rename_map = {f'P_{col}': f'P{col}' for col in generic_cols}\n",
        "    home_prev_data.rename(columns=home_rename_map, inplace=True)\n",
        "    cols_to_merge_home = ['match_id', 'HomeTeam'] + list(home_rename_map.values())\n",
        "    df_out = df_out.merge(home_prev_data[cols_to_merge_home], on=['match_id', 'HomeTeam'], how='left')\n",
        "\n",
        "    # --- Merge for Away teams ---\n",
        "    away_prev_data = all_stats_df[all_stats_df['is_home_match'] == 0].copy()\n",
        "    away_prev_data.rename(columns={'Team': 'AwayTeam'}, inplace=True)\n",
        "    # Rename columns: 'P_HST' -> 'PAST' (uses the 'away_stat' name)\n",
        "    away_rename_map = {}\n",
        "    for home_stat, away_stat in stats_map.items():\n",
        "        away_rename_map[f'P_{home_stat}'] = f'P{away_stat}' # e.g., 'P_HST' -> 'PAST'\n",
        "    away_prev_data.rename(columns=away_rename_map, inplace=True)\n",
        "    cols_to_merge_away = ['match_id', 'AwayTeam'] + list(away_rename_map.values())\n",
        "    df_out = df_out.merge(away_prev_data[cols_to_merge_away], on=['match_id', 'AwayTeam'], how='left')\n",
        "\n",
        "    return df_out\n",
        "\n",
        "\n",
        "\n",
        "def get_time_between_games(df):\n",
        "    \"\"\"\n",
        "    Calculates the number of days since the last match for\n",
        "    the home and away teams (TBGH, TBGA).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_out = df.copy()\n",
        "\n",
        "    base_cols = ['TBGH', 'TBGA']\n",
        "\n",
        "    cols_to_drop = []\n",
        "    for col_in_df in df_out.columns:\n",
        "        base_name = col_in_df.split('_x')[0].split('_y')[0]\n",
        "        if base_name in base_cols:\n",
        "            cols_to_drop.append(col_in_df)\n",
        "\n",
        "    if cols_to_drop:\n",
        "        df_out = df_out.drop(columns=list(set(cols_to_drop)))\n",
        "\n",
        "\n",
        "    # 1.\n",
        "    home_df = df_out[['match_id', 'Date', 'HomeTeam']].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "\n",
        "    away_df = df_out[['match_id', 'Date', 'AwayTeam']].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "\n",
        "    # 2.\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3.\n",
        "    all_stats_df['Prev_Date'] = all_stats_df.groupby('Team')['Date'].shift(1)\n",
        "\n",
        "    # Ensureing both columns are datetime objects before subtraction\n",
        "    all_stats_df['Date'] = pd.to_datetime(all_stats_df['Date'], errors='coerce')\n",
        "    all_stats_df['Prev_Date'] = pd.to_datetime(all_stats_df['Prev_Date'], errors='coerce')\n",
        "\n",
        "    # b.\n",
        "    all_stats_df['TBG'] = (all_stats_df['Date'] - all_stats_df['Prev_Date']).dt.days\n",
        "\n",
        "    all_stats_df = all_stats_df.sort_values(by='Date')\n",
        "\n",
        "    # 4.\n",
        "    home_prev_data = all_stats_df[all_stats_df['is_home_match'] == 1].copy()\n",
        "    home_prev_data.rename(columns={'Team': 'HomeTeam', 'TBG': 'TBGH'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_home = ['match_id', 'HomeTeam', 'TBGH']\n",
        "    df_out = df_out.merge(\n",
        "        home_prev_data[cols_to_merge_home],\n",
        "        on=['match_id', 'HomeTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    away_prev_data = all_stats_df[all_stats_df['is_home_match'] == 0].copy()\n",
        "    away_prev_data.rename(columns={'Team': 'AwayTeam', 'TBG': 'TBGA'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_away = ['match_id', 'AwayTeam', 'TBGA']\n",
        "    df_out = df_out.merge(\n",
        "        away_prev_data[cols_to_merge_away],\n",
        "        on=['match_id', 'AwayTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def get_number_of_wins(df, window_size=3):\n",
        "    \"\"\"\n",
        "    Calculates the *number* of wins in the last 'window_size' games\n",
        "    (NOWH, NOWA).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_out = df.copy()\n",
        "\n",
        "    base_cols = ['NOWH', 'NOWA']\n",
        "\n",
        "    cols_to_drop = []\n",
        "    for col_in_df in df_out.columns:\n",
        "        base_name = col_in_df.split('_x')[0].split('_y')[0]\n",
        "        if base_name in base_cols:\n",
        "            cols_to_drop.append(col_in_df)\n",
        "\n",
        "    if cols_to_drop:\n",
        "        df_out = df_out.drop(columns=list(set(cols_to_drop)))\n",
        "\n",
        "\n",
        "    # 1.\n",
        "    home_df = df_out[['match_id', 'Date', 'HomeTeam', 'FTR']].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "    home_df['Won'] = (home_df['FTR'] == 'H').astype(int)\n",
        "\n",
        "    away_df = df_out[['match_id', 'Date', 'AwayTeam', 'FTR']].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "    away_df['Won'] = (away_df['FTR'] == 'A').astype(int)\n",
        "\n",
        "    # 2. concate and sort\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3. Calculate the rolling *sum* of wins\n",
        "    rolling_sum_series = all_stats_df.groupby('Team')['Won'] \\\n",
        "                                     .rolling(window=window_size) \\\n",
        "                                     .sum()\n",
        "    rolling_sum_series = rolling_sum_series.reset_index(level=0, drop=True)\n",
        "\n",
        "    all_stats_df['TEMP_NOW'] = rolling_sum_series\n",
        "\n",
        "    all_stats_df['NOW'] = all_stats_df.groupby('Team')['TEMP_NOW'].shift(1)\n",
        "\n",
        "    # 4. sort back\n",
        "    all_stats_df = all_stats_df.sort_values(by='Date')\n",
        "\n",
        "    # 5. Merge back\n",
        "\n",
        "    home_prev_data = all_stats_df[all_stats_df['is_home_match'] == 1].copy()\n",
        "    home_prev_data.rename(columns={'Team': 'HomeTeam', 'NOW': 'NOWH'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_home = ['match_id', 'HomeTeam', 'NOWH']\n",
        "    df_out = df_out.merge(\n",
        "        home_prev_data[cols_to_merge_home],\n",
        "        on=['match_id', 'HomeTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    away_prev_data = all_stats_df[all_stats_df['is_home_match'] == 0].copy()\n",
        "    away_prev_data.rename(columns={'Team': 'AwayTeam', 'NOW': 'NOWA'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_away = ['match_id', 'AwayTeam', 'NOWA']\n",
        "    df_out = df_out.merge(\n",
        "        away_prev_data[cols_to_merge_away],\n",
        "        on=['match_id', 'AwayTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    df_out = df_out.drop(columns=['NOWH_x', 'NOWA_x', 'NOWH_y', 'NOWA_y'], errors='ignore')\n",
        "\n",
        "    return df_out\n",
        "\n",
        "\n",
        "def get_avg_time_between_games(df, window_size=3):\n",
        "    \"\"\"\n",
        "    Calculates the *average* number of days since the\n",
        "    last 'window_size' games (ATBGH, ATBGA).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_out = df.copy()\n",
        "\n",
        "    base_cols = ['ATBGH', 'ATBGA']\n",
        "\n",
        "    cols_to_drop = []\n",
        "    for col_in_df in df_out.columns:\n",
        "        base_name = col_in_df.split('_x')[0].split('_y')[0]\n",
        "        if base_name in base_cols:\n",
        "            cols_to_drop.append(col_in_df)\n",
        "\n",
        "    if cols_to_drop:\n",
        "        df_out = df_out.drop(columns=list(set(cols_to_drop)))\n",
        "\n",
        "\n",
        "    # 1. Create long version\n",
        "    home_df = df_out[['match_id', 'Date', 'HomeTeam']].copy()\n",
        "    home_df.rename(columns={'HomeTeam': 'Team'}, inplace=True)\n",
        "    home_df['is_home_match'] = 1\n",
        "\n",
        "    away_df = df_out[['match_id', 'Date', 'AwayTeam']].copy()\n",
        "    away_df.rename(columns={'AwayTeam': 'Team'}, inplace=True)\n",
        "    away_df['is_home_match'] = 0\n",
        "\n",
        "    # 2. Concate and sort\n",
        "    all_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
        "    all_stats_df = all_stats_df.sort_values(by=['Team', 'Date'])\n",
        "\n",
        "    # 3. Calculate 'TBG' (Time Between Games)\n",
        "    all_stats_df['Prev_Date'] = all_stats_df.groupby('Team')['Date'].shift(1)\n",
        "\n",
        "    # Ensureing both columns are datetime objects before subtraction\n",
        "    all_stats_df['Date'] = pd.to_datetime(all_stats_df['Date'], errors='coerce')\n",
        "    all_stats_df['Prev_Date'] = pd.to_datetime(all_stats_df['Prev_Date'], errors='coerce')\n",
        "\n",
        "    all_stats_df['TBG'] = (all_stats_df['Date'] - all_stats_df['Prev_Date']).dt.days.fillna(110)\n",
        "\n",
        "    # 4. Applying rolling averages 'TBG' anwenden\n",
        "    rolling_avg_series = all_stats_df.groupby('Team')['TBG'] \\\n",
        "                                     .rolling(window=window_size) \\\n",
        "                                     .mean()\n",
        "    rolling_avg_series = rolling_avg_series.reset_index(level=0, drop=True)\n",
        "\n",
        "    all_stats_df['TEMP_ATBG'] = rolling_avg_series\n",
        "\n",
        "    all_stats_df['ATBG'] = all_stats_df.groupby('Team')['TEMP_ATBG'].shift(1)\n",
        "\n",
        "    # 5. sort back\n",
        "    all_stats_df = all_stats_df.sort_values(by='Date')\n",
        "\n",
        "    # 6. merge back\n",
        "\n",
        "    home_prev_data = all_stats_df[all_stats_df['is_home_match'] == 1].copy()\n",
        "    home_prev_data.rename(columns={'Team': 'HomeTeam', 'ATBG': 'ATBGH'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_home = ['match_id', 'HomeTeam', 'ATBGH']\n",
        "    df_out = df_out.merge(\n",
        "        home_prev_data[cols_to_merge_home],\n",
        "        on=['match_id', 'HomeTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    away_prev_data = all_stats_df[all_stats_df['is_home_match'] == 0].copy()\n",
        "    away_prev_data.rename(columns={'Team': 'AwayTeam', 'ATBG': 'ATBGA'}, inplace=True)\n",
        "\n",
        "    cols_to_merge_away = ['match_id', 'AwayTeam', 'ATBGA']\n",
        "    df_out = df_out.merge(\n",
        "        away_prev_data[cols_to_merge_away],\n",
        "        on=['match_id', 'AwayTeam'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    df_out = df_out.drop(columns=['TBGH_x', 'TBGA_x', 'TBGH_y', 'TBGA_y'], errors='ignore')\n",
        "\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494bbC11GlE6"
      },
      "source": [
        "Additional features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "C9iNDgFRyyiX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_ewma_momentum(df, span=3):\n",
        "    \"\"\"\n",
        "    Calculates momentum using Exponentially Weighted Moving Average of points.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe containing match statistics.\n",
        "        span: The span (window size equivalent) for the EWMA.\n",
        "              A span of 3 roughly corresponds to the 'center of mass' of a 3-match window.\n",
        "\n",
        "    Returns:\n",
        "        df: The dataframe with new columns 'HomeMomentum' and 'AwayMomentum'.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Create a long-format dataframe of all matches from the team's perspective\n",
        "    # Home Stats\n",
        "    home_df = df[['Date', 'HomeTeam', 'FTR']].rename(columns={'HomeTeam': 'Team'})\n",
        "    home_df['Points'] = np.where(df['FTR'] == 'H', 3,\n",
        "                                 np.where(df['FTR'] == 'D', 1, 0))\n",
        "    home_df['IsHome'] = True\n",
        "    home_df['MatchIndex'] = df.index\n",
        "\n",
        "    # Away Stats\n",
        "    away_df = df[['Date', 'AwayTeam', 'FTR']].rename(columns={'AwayTeam': 'Team'})\n",
        "    away_df['Points'] = np.where(df['FTR'] == 'A', 3,\n",
        "                                 np.where(df['FTR'] == 'D', 1, 0))\n",
        "    away_df['IsHome'] = False\n",
        "    away_df['MatchIndex'] = df.index\n",
        "\n",
        "    # Concatenate to get a single timeline per team\n",
        "    teams_df = pd.concat([home_df, away_df]).sort_values(['Team', 'Date'])\n",
        "\n",
        "    # 2. Calculate EWMA Momentum\n",
        "    teams_df['Momentum_EWMA'] = teams_df.groupby('Team')['Points'].transform(\n",
        "        lambda x: x.ewm(span=span, adjust=False).mean().shift(1)\n",
        "    )\n",
        "\n",
        "    # 3. Merge back into the original dataframe structure\n",
        "    # Retrieve Home Momentum\n",
        "    home_momentum = teams_df[teams_df['IsHome'] == True].set_index('MatchIndex')['Momentum_EWMA']\n",
        "    df['HomeMomentum'] = home_momentum\n",
        "\n",
        "    # Retrieve Away Momentum\n",
        "    away_momentum = teams_df[teams_df['IsHome'] == False].set_index('MatchIndex')['Momentum_EWMA']\n",
        "    df['AwayMomentum'] = away_momentum\n",
        "\n",
        "    # Fill NaN values (first match of the season) with a default (e.g., 1 point or 0)\n",
        "    df[['HomeMomentum', 'AwayMomentum']] = df[['HomeMomentum', 'AwayMomentum']].fillna(1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i5AHIqTiGjXU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_travel_distance_feature(df, coords_dict):\n",
        "    \"\"\"\n",
        "    Adds a column to the DataFrame for the away team's travel distance.\n",
        "    Assumeing the home team has a travel distance of 0.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Help function: Haversine-Formel for Distance on earth\n",
        "    def haversine_np(lon1, lat1, lon2, lat2):\n",
        "        \"\"\"\n",
        "        Calculates the great circle distance between two points\n",
        "        on Earth (given in decimal degrees).\n",
        "        \"\"\"\n",
        "        # Calculating to radius\n",
        "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "        # Haversine-Formel\n",
        "        dlon = lon2 - lon1\n",
        "        dlat = lat2 - lat1\n",
        "        a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "        c = 2 * np.arcsin(np.sqrt(a))\n",
        "        km = 6371 * c  # Radius of earth in km\n",
        "        return km\n",
        "\n",
        "    # 2. Coordinates mapping\n",
        "\n",
        "    # Heim-Coordinates\n",
        "    df['HomeLat'] = df['HomeTeam'].map(lambda x: coords_dict.get(x, (np.nan, np.nan))[0])\n",
        "    df['HomeLon'] = df['HomeTeam'].map(lambda x: coords_dict.get(x, (np.nan, np.nan))[1])\n",
        "\n",
        "    # AuswÃ¤rts-Coordinates\n",
        "    df['AwayLat'] = df['AwayTeam'].map(lambda x: coords_dict.get(x, (np.nan, np.nan))[0])\n",
        "    df['AwayLon'] = df['AwayTeam'].map(lambda x: coords_dict.get(x, (np.nan, np.nan))[1])\n",
        "\n",
        "    # 3. Calculate distance\n",
        "    df['AwayDistTravelled'] = haversine_np(\n",
        "        df['HomeLon'], df['HomeLat'],\n",
        "        df['AwayLon'], df['AwayLat']\n",
        "    )\n",
        "\n",
        "    if df['AwayDistTravelled'].isna().sum() > 0:\n",
        "        mean_dist = df['AwayDistTravelled'].mean()\n",
        "        print(f\"Warning: {df['AwayDistTravelled'].isna().sum()} missing distance is average of all({mean_dist:.2f} km).\")\n",
        "        df['AwayDistTravelled'].fillna(mean_dist, inplace=True)\n",
        "\n",
        "    # 4. Clean up\n",
        "    df.drop(['HomeLat', 'HomeLon', 'AwayLat', 'AwayLon'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "stadium_coordinates = {\n",
        "    \"Arsenal\": (51.555, -0.1086),\n",
        "    \"Bournemouth\": (50.735, -1.838),\n",
        "    \"Brighton\": (50.862, -0.083),\n",
        "    \"Burnley\": (53.789, -2.230),\n",
        "    \"Chelsea\": (51.4816, -0.1908),\n",
        "    \"Crystal Palace\": (51.3983, -0.0855),\n",
        "    \"Everton\": (53.4389, -2.9664),\n",
        "    \"Huddersfield\": (53.654, -1.768),\n",
        "    \"Leicester\": (52.6203, -1.1422),\n",
        "    \"Liverpool\": (53.4308, -2.9608),\n",
        "    \"Man City\": (53.4830, -2.2002),\n",
        "    \"Man United\": (53.4631, -2.2913),\n",
        "    \"Newcastle\": (54.9756, -1.6217),\n",
        "    \"Southampton\": (50.9058, -1.3911),\n",
        "    \"Stoke\": (52.9883, -2.1755),\n",
        "    \"Swansea\": (51.6422, -3.9347),\n",
        "    \"Tottenham\": (51.6042, -0.0662),\n",
        "    \"Watford\": (51.6497, -0.4014),\n",
        "    \"West Brom\": (52.5091, -1.9639),\n",
        "    \"West Ham\": (51.5386, -0.0165),\n",
        "    \"Cardiff\": (51.4728, -3.2031),\n",
        "    \"Fulham\": (51.4749, -0.2217),\n",
        "    \"Wolves\": (52.5902, -2.1303),\n",
        "    \"Aston Villa\": (52.5091, -1.8847),\n",
        "    \"Norwich\": (52.6222, 1.3092),\n",
        "    \"Sheffield United\": (53.3703, -1.4708),\n",
        "    \"Leeds\": (53.7778, -1.5722),\n",
        "    \"Brentford\": (51.490833, -0.288611)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C3zthndf_v8"
      },
      "source": [
        "Pipeline to create the dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gjyIY9sugSiW"
      },
      "outputs": [],
      "source": [
        "def feature_engineering_pipeline(input_df, window_size=3):\n",
        "    \"\"\"\n",
        "    Executes all feature engineering steps sequentially.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Starting pipeline with {input_df.shape[0]} matches...\")\n",
        "    df = input_df.copy()\n",
        "\n",
        "    # --- 1. Define Stat-Mapping ---\n",
        "    # (Home Stat : Away Stat)\n",
        "    avg_stats_map = {\n",
        "        'FTHG': 'FTAG',\n",
        "        'HS': 'AS',\n",
        "        'HST': 'AST',\n",
        "        'HC': 'AC',\n",
        "        'HF': 'AF',\n",
        "        'HY': 'AY',\n",
        "        'HR': 'AR'\n",
        "    }\n",
        "\n",
        "    # --- 2. Call functions sequentially ---\n",
        "\n",
        "    print(\"Classifying kickoff time (TMKO)...\")\n",
        "    df = classify_kickoff_time(df)\n",
        "\n",
        "    print(\"Calculating rolling average...\")\n",
        "    df = get_strict_rolling_avg(df, avg_stats_map, window_size=window_size)\n",
        "\n",
        "    print(\"Calculating form (last match)...\")\n",
        "    df = get_previous_game_form(df)\n",
        "\n",
        "    print(\"Calculating last match stats...\")\n",
        "    df = get_last_match_overall(df, avg_stats_map)\n",
        "\n",
        "    print(\"Calculating time between games (TBGH, TBGA)...\")\n",
        "    df = get_time_between_games(df)\n",
        "\n",
        "    print(\"Calculating number of wins in the last 3 games (NOWH, NOWA)\")\n",
        "    df = get_number_of_wins(df, window_size=window_size)\n",
        "\n",
        "    print(\"claculation avarage time between games\")\n",
        "    df = get_avg_time_between_games(df, window_size=window_size)\n",
        "\n",
        "    print(\"Calculating momentum through exponentially weighted moving averages\")\n",
        "    df = calculate_ewma_momentum(df, span=3)\n",
        "\n",
        "    print(\"Calculationg fatigues with travel distance\")\n",
        "    df = add_travel_distance_feature(df, stadium_coordinates)\n",
        "\n",
        "    print(\"Pipeline finished.\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk9Y_6j8gUNT",
        "outputId": "69a085b1-c0d8-4c2d-8f33-c3c7ee43fa0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting pipeline with 1140 matches...\n",
            "Classifying kickoff time (TMKO)...\n",
            "Calculating rolling average...\n",
            "Calculating form (last match)...\n",
            "Calculating last match stats...\n",
            "Calculating time between games (TBGH, TBGA)...\n",
            "Calculating number of wins in the last 3 games (NOWH, NOWA)\n",
            "claculation avarage time between games\n",
            "Calculating momentum through exponentially weighted moving averages\n",
            "Calculationg fatigues with travel distance\n",
            "Pipeline finished.\n",
            "\n",
            "--- Result DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1140 entries, 0 to 1139\n",
            "Data columns (total 82 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   Date                            1140 non-null   object \n",
            " 1   Time                            1140 non-null   object \n",
            " 2   HomeTeam                        1140 non-null   object \n",
            " 3   AwayTeam                        1140 non-null   object \n",
            " 4   FTR                             1140 non-null   object \n",
            " 5   FTHG                            1140 non-null   int64  \n",
            " 6   FTAG                            1140 non-null   int64  \n",
            " 7   HS                              1140 non-null   int64  \n",
            " 8   AS                              1140 non-null   int64  \n",
            " 9   HST                             1140 non-null   int64  \n",
            " 10  AST                             1140 non-null   int64  \n",
            " 11  HC                              1140 non-null   int64  \n",
            " 12  AC                              1140 non-null   int64  \n",
            " 13  HF                              1140 non-null   int64  \n",
            " 14  AF                              1140 non-null   int64  \n",
            " 15  HY                              1140 non-null   int64  \n",
            " 16  AY                              1140 non-null   int64  \n",
            " 17  HR                              1140 non-null   int64  \n",
            " 18  AR                              1140 non-null   int64  \n",
            " 19  Start_Temp_C                    1140 non-null   float64\n",
            " 20  Start_Wind_kmh                  1140 non-null   float64\n",
            " 21  Start_Wind_Degree               1140 non-null   int64  \n",
            " 22  Start_Humidity                  1140 non-null   int64  \n",
            " 23  Start_Precip_mm                 1140 non-null   float64\n",
            " 24  match_id                        1140 non-null   int64  \n",
            " 25  Start_Conditions_clear_sky      1140 non-null   int64  \n",
            " 26  Start_Conditions_cloudy         1140 non-null   int64  \n",
            " 27  Start_Conditions_fog            1140 non-null   int64  \n",
            " 28  Start_Conditions_heavy_rain     1140 non-null   int64  \n",
            " 29  Start_Conditions_moderate_rain  1140 non-null   int64  \n",
            " 30  Start_Conditions_rain           1140 non-null   int64  \n",
            " 31  Start_Conditions_snow           1140 non-null   int64  \n",
            " 32  Start_Conditions_thunderstorm   1140 non-null   int64  \n",
            " 33  End_Conditions_clear_sky        1140 non-null   int64  \n",
            " 34  End_Conditions_cloudy           1140 non-null   int64  \n",
            " 35  End_Conditions_fog              1140 non-null   int64  \n",
            " 36  End_Conditions_heavy_rain       1140 non-null   int64  \n",
            " 37  End_Conditions_moderate_rain    1140 non-null   int64  \n",
            " 38  End_Conditions_rain             1140 non-null   int64  \n",
            " 39  End_Conditions_snow             1140 non-null   int64  \n",
            " 40  TMKO                            1140 non-null   int64  \n",
            " 41  AFTHG                           1104 non-null   float64\n",
            " 42  AHS                             1104 non-null   float64\n",
            " 43  AHST                            1104 non-null   float64\n",
            " 44  AHC                             1104 non-null   float64\n",
            " 45  AHF                             1104 non-null   float64\n",
            " 46  AHY                             1104 non-null   float64\n",
            " 47  AHR                             1104 non-null   float64\n",
            " 48  AFTAG                           1104 non-null   float64\n",
            " 49  AAS                             1104 non-null   float64\n",
            " 50  AAST                            1104 non-null   float64\n",
            " 51  AAC                             1104 non-null   float64\n",
            " 52  AAF                             1104 non-null   float64\n",
            " 53  AAY                             1104 non-null   float64\n",
            " 54  AAR                             1104 non-null   float64\n",
            " 55  PHFR_Won                        1127 non-null   float64\n",
            " 56  PHFR_NotWin                     1127 non-null   float64\n",
            " 57  PAFR_Won                        1129 non-null   float64\n",
            " 58  PAFR_NotWin                     1129 non-null   float64\n",
            " 59  PFTHG                           1127 non-null   float64\n",
            " 60  PHS                             1127 non-null   float64\n",
            " 61  PHST                            1127 non-null   float64\n",
            " 62  PHC                             1127 non-null   float64\n",
            " 63  PHF                             1127 non-null   float64\n",
            " 64  PHY                             1127 non-null   float64\n",
            " 65  PHR                             1127 non-null   float64\n",
            " 66  PFTAG                           1129 non-null   float64\n",
            " 67  PAS                             1129 non-null   float64\n",
            " 68  PAST                            1129 non-null   float64\n",
            " 69  PAC                             1129 non-null   float64\n",
            " 70  PAF                             1129 non-null   float64\n",
            " 71  PAY                             1129 non-null   float64\n",
            " 72  PAR                             1129 non-null   float64\n",
            " 73  TBGH                            1127 non-null   float64\n",
            " 74  TBGA                            1129 non-null   float64\n",
            " 75  NOWH                            1104 non-null   float64\n",
            " 76  NOWA                            1104 non-null   float64\n",
            " 77  ATBGH                           1104 non-null   float64\n",
            " 78  ATBGA                           1104 non-null   float64\n",
            " 79  HomeMomentum                    1140 non-null   float64\n",
            " 80  AwayMomentum                    1140 non-null   float64\n",
            " 81  AwayDistTravelled               1140 non-null   float64\n",
            "dtypes: float64(44), int64(33), object(5)\n",
            "memory usage: 730.4+ KB\n",
            "\n",
            "--- Example Data (Mid-Season) ---\n",
            "      Time  TMKO     HomeTeam    AwayTeam  HST  AST      AHST      AAST  \\\n",
            "100  15:00     0     West Ham   Newcastle    6    9  4.000000  1.333333   \n",
            "101  12:30     0  Bournemouth  Man United    6    4  3.000000  5.333333   \n",
            "102  15:00     0      Arsenal      Wolves    4    8  3.666667  2.666667   \n",
            "103  15:00     0  Aston Villa   Liverpool    2    6  8.333333  8.333333   \n",
            "104  15:00     0     Brighton     Norwich    5    0  5.000000  3.000000   \n",
            "\n",
            "     PHFR_Won  PAFR_Won  PHST  PAST  \n",
            "100       0.0       0.0   4.0   2.0  \n",
            "101       0.0       1.0   5.0  11.0  \n",
            "102       0.0       0.0   6.0   5.0  \n",
            "103       0.0       1.0   5.0  13.0  \n",
            "104       1.0       0.0   4.0   3.0  \n"
          ]
        }
      ],
      "source": [
        "# --- 4. EXECUTE PIPELINE ---\n",
        "features_df = feature_engineering_pipeline(playing_stat, window_size=3)\n",
        "features_df.to_csv(\"features_df.csv\", index= False)\n",
        "\n",
        "# --- 5. CHECK RESULT ---\n",
        "\n",
        "print(\"\\n--- Result DataFrame Info ---\")\n",
        "features_df.info()\n",
        "\n",
        "# Example columns to verify the result\n",
        "print(\"\\n--- Example Data (Mid-Season) ---\")\n",
        "example_cols = [\n",
        "    'Time', 'TMKO',       #From classify_kickoff_time\n",
        "    'HomeTeam', 'AwayTeam',\n",
        "    'HST', 'AST',         # Original\n",
        "    'AHST', 'AAST',      # From get_strict_rolling_avg\n",
        "    'PHFR_Won', 'PAFR_Won', # From get_previous_game_form\n",
        "    'PHST', 'PAST'        # From get_last_match_overall\n",
        "]\n",
        "\n",
        "# Show games from mid-season (should have values)\n",
        "print(features_df[example_cols].iloc[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-qTFcfBt5wK",
        "outputId": "83401543-29a7-406d-e4b6-5e8141ac6a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Time', 'HomeTeam', 'AwayTeam', 'FTR', 'FTHG', 'FTAG', 'HS',\n",
              "       'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR',\n",
              "       'Start_Temp_C', 'Start_Wind_kmh', 'Start_Wind_Degree', 'Start_Humidity',\n",
              "       'Start_Precip_mm', 'match_id', 'Start_Conditions_clear_sky',\n",
              "       'Start_Conditions_cloudy', 'Start_Conditions_fog',\n",
              "       'Start_Conditions_heavy_rain', 'Start_Conditions_moderate_rain',\n",
              "       'Start_Conditions_rain', 'Start_Conditions_snow',\n",
              "       'Start_Conditions_thunderstorm', 'End_Conditions_clear_sky',\n",
              "       'End_Conditions_cloudy', 'End_Conditions_fog',\n",
              "       'End_Conditions_heavy_rain', 'End_Conditions_moderate_rain',\n",
              "       'End_Conditions_rain', 'End_Conditions_snow', 'TMKO', 'AFTHG', 'AHS',\n",
              "       'AHST', 'AHC', 'AHF', 'AHY', 'AHR', 'AFTAG', 'AAS', 'AAST', 'AAC',\n",
              "       'AAF', 'AAY', 'AAR', 'PHFR_Won', 'PHFR_NotWin', 'PAFR_Won',\n",
              "       'PAFR_NotWin', 'PFTHG', 'PHS', 'PHST', 'PHC', 'PHF', 'PHY', 'PHR',\n",
              "       'PFTAG', 'PAS', 'PAST', 'PAC', 'PAF', 'PAY', 'PAR', 'TBGH', 'TBGA',\n",
              "       'NOWH', 'NOWA', 'ATBGH', 'ATBGA', 'HomeMomentum', 'AwayMomentum',\n",
              "       'AwayDistTravelled'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "features_df.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ34OUcH7jLD"
      },
      "source": [
        "# Using features:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "gg_D526xuiPH"
      },
      "outputs": [],
      "source": [
        "basic_features = ['TMKO', 'AFTHG', 'AHS',\n",
        "       'AHST', 'AHC', 'AHF', 'AHY', 'AHR', 'AFTAG', 'AAS', 'AAST', 'AAC',\n",
        "       'AAF', 'AAY', 'AAR', 'PHFR_Won', 'PHFR_NotWin', 'PAFR_Won',\n",
        "       'PAFR_NotWin', 'PFTHG', 'PHS', 'PHST', 'PHC', 'PHF', 'PHY', 'PHR',\n",
        "       'PFTAG', 'PAS', 'PAST', 'PAC', 'PAF', 'PAY', 'PAR', 'TBGH', 'TBGA',\n",
        "       'NOWH', 'NOWA',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xt-iKwnGusig"
      },
      "outputs": [],
      "source": [
        "weather_start = ['Start_Temp_C', 'Start_Wind_kmh', 'Start_Wind_Degree', 'Start_Humidity', 'Start_Precip_mm', 'Start_Conditions_clear_sky',\n",
        "       'Start_Conditions_cloudy', 'Start_Conditions_fog',\n",
        "       'Start_Conditions_heavy_rain', 'Start_Conditions_moderate_rain',\n",
        "       'Start_Conditions_rain', 'Start_Conditions_snow',\n",
        "       'Start_Conditions_thunderstorm',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1DzHApSewHLT"
      },
      "outputs": [],
      "source": [
        "weather_end = ['End_Conditions_clear_sky',\n",
        "       'End_Conditions_cloudy', 'End_Conditions_fog',\n",
        "       'End_Conditions_heavy_rain', 'End_Conditions_moderate_rain',\n",
        "       'End_Conditions_rain', 'End_Conditions_snow',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QPJcXAutxfir"
      },
      "outputs": [],
      "source": [
        "features_added = ['HomeMomentum', 'AwayMomentum', 'AwayDistTravelled']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ydfpKMnIxAyO"
      },
      "outputs": [],
      "source": [
        "features = (basic_features\n",
        "            + weather_start\n",
        "            + weather_end\n",
        "            + features_added\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTuRhBpK7soZ"
      },
      "source": [
        "# Training, Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "yrVqa6Se7v2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cff0df1-8e4a-4644-9607-2efee4a29496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training till 2021-08-12: 722 games\n",
            "Testing since 2021-08-12: 377 games\n"
          ]
        }
      ],
      "source": [
        "# 1. Clean up to length\n",
        "df_clean = features_df.dropna().copy()\n",
        "df_clean.to_csv(\"clean_90.csv\", index=False)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Ensure the date is in the correct format\n",
        "df_clean['Date'] = pd.to_datetime(df_clean['Date'])\n",
        "\n",
        "# 2. Create a target variable (1 = home win, 0 = no home win)\n",
        "df_clean['HomeWin_Binary'] = df_clean['FTR'].apply(lambda x: 1 if x == 'H' else 0)\n",
        "\n",
        "# 3. Chronological split (time separation)\n",
        "split_date = '2021-08-12'\n",
        "\n",
        "# Everything before or on August 13, 2021 is training.\n",
        "train_df = df_clean[df_clean['Date'] <= split_date].copy()\n",
        "\n",
        "# Everything after is testing\n",
        "test_df = df_clean[df_clean['Date'] > split_date].copy()\n",
        "\n",
        "print(f\"Training till {split_date}: {len(train_df)} games\")\n",
        "print(f\"Testing since {split_date}: {len(test_df)} games\")\n",
        "\n",
        "# 4. Assign features and targets\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['HomeWin_Binary']\n",
        "\n",
        "X_test = test_df[features]\n",
        "# Adjusting for consistency with paper\n",
        "X_test = X_test.iloc[27:]\n",
        "y_test = test_df['HomeWin_Binary']\n",
        "y_test = y_test.iloc[27:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dXjqGuhqRjP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abee0c3-e236-4e39-81c4-00f3c7ba1304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((722, 60), (722,), (350, 60), (350,))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCfX4r2A71PD"
      },
      "source": [
        "# Fitting the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "UJQcHjzImu66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2a6916-5d4f-42fb-dffb-57c428faa8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4VGP06DO72a1"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import svm\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "RlbJFQUE76rY"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name=\"Modell\"):\n",
        "    # 1. Training\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 2. Prediction\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 3. Calculate metrcs\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    # 4. Results\n",
        "    print(f\"\\n{'='*10} Results: {model_name} {'='*10}\")\n",
        "    print(f\"TP (True home victory detected): {tp}\")\n",
        "    print(f\"TN (No win detected): {tn}\")\n",
        "    print(f\"FP (False alarm):          {fp}\")\n",
        "    print(f\"FN (Missed home victory):           {fn}\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"MCC:       {mcc:.4f}\")\n",
        "    print(\"\\n=== Classification Report ===\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "id": "kef2Q79f79gd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e023b0-92c6-488c-9848-422bd2865580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "\n",
            "========== Results: Logistic Regression ==========\n",
            "TP (True home victory detected): 61\n",
            "TN (No win detected): 156\n",
            "FP (False alarm):          45\n",
            "FN (Missed home victory):           88\n",
            "------------------------------\n",
            "Accuracy:  0.6200\n",
            "Precision: 0.5755\n",
            "Recall:    0.4094\n",
            "F1-Score:  0.4784\n",
            "MCC:       0.1996\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.78      0.70       201\n",
            "           1       0.58      0.41      0.48       149\n",
            "\n",
            "    accuracy                           0.62       350\n",
            "   macro avg       0.61      0.59      0.59       350\n",
            "weighted avg       0.61      0.62      0.61       350\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "========== Results: Random Forest ==========\n",
            "TP (True home victory detected): 49\n",
            "TN (No win detected): 169\n",
            "FP (False alarm):          32\n",
            "FN (Missed home victory):           100\n",
            "------------------------------\n",
            "Accuracy:  0.6229\n",
            "Precision: 0.6049\n",
            "Recall:    0.3289\n",
            "F1-Score:  0.4261\n",
            "MCC:       0.1989\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.84      0.72       201\n",
            "           1       0.60      0.33      0.43       149\n",
            "\n",
            "    accuracy                           0.62       350\n",
            "   macro avg       0.62      0.58      0.57       350\n",
            "weighted avg       0.62      0.62      0.59       350\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "========== Results: SVM ==========\n",
            "TP (True home victory detected): 94\n",
            "TN (No win detected): 118\n",
            "FP (False alarm):          83\n",
            "FN (Missed home victory):           55\n",
            "------------------------------\n",
            "Accuracy:  0.6057\n",
            "Precision: 0.5311\n",
            "Recall:    0.6309\n",
            "F1-Score:  0.5767\n",
            "MCC:       0.2155\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.59      0.63       201\n",
            "           1       0.53      0.63      0.58       149\n",
            "\n",
            "    accuracy                           0.61       350\n",
            "   macro avg       0.61      0.61      0.60       350\n",
            "weighted avg       0.62      0.61      0.61       350\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "========== Results: XGBoost ==========\n",
            "TP (True home victory detected): 47\n",
            "TN (No win detected): 182\n",
            "FP (False alarm):          19\n",
            "FN (Missed home victory):           102\n",
            "------------------------------\n",
            "Accuracy:  0.6543\n",
            "Precision: 0.7121\n",
            "Recall:    0.3154\n",
            "F1-Score:  0.4372\n",
            "MCC:       0.2792\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.91      0.75       201\n",
            "           1       0.71      0.32      0.44       149\n",
            "\n",
            "    accuracy                           0.65       350\n",
            "   macro avg       0.68      0.61      0.59       350\n",
            "weighted avg       0.67      0.65      0.62       350\n",
            "\n",
            "Training Gradient Boosting (GBM)...\n",
            "\n",
            "========== Results: Gradient Boosting (GBM) ==========\n",
            "TP (True home victory detected): 60\n",
            "TN (No win detected): 143\n",
            "FP (False alarm):          58\n",
            "FN (Missed home victory):           89\n",
            "------------------------------\n",
            "Accuracy:  0.5800\n",
            "Precision: 0.5085\n",
            "Recall:    0.4027\n",
            "F1-Score:  0.4494\n",
            "MCC:       0.1194\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.66       201\n",
            "           1       0.51      0.40      0.45       149\n",
            "\n",
            "    accuracy                           0.58       350\n",
            "   macro avg       0.56      0.56      0.55       350\n",
            "weighted avg       0.57      0.58      0.57       350\n",
            "\n",
            "Training LightGBM...\n",
            "\n",
            "========== Results: LightGBM ==========\n",
            "TP (True home victory detected): 70\n",
            "TN (No win detected): 144\n",
            "FP (False alarm):          57\n",
            "FN (Missed home victory):           79\n",
            "------------------------------\n",
            "Accuracy:  0.6114\n",
            "Precision: 0.5512\n",
            "Recall:    0.4698\n",
            "F1-Score:  0.5072\n",
            "MCC:       0.1915\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.72      0.68       201\n",
            "           1       0.55      0.47      0.51       149\n",
            "\n",
            "    accuracy                           0.61       350\n",
            "   macro avg       0.60      0.59      0.59       350\n",
            "weighted avg       0.61      0.61      0.61       350\n",
            "\n",
            "Training CatBoost...\n",
            "\n",
            "========== Results: CatBoost ==========\n",
            "TP (True home victory detected): 53\n",
            "TN (No win detected): 164\n",
            "FP (False alarm):          37\n",
            "FN (Missed home victory):           96\n",
            "------------------------------\n",
            "Accuracy:  0.6200\n",
            "Precision: 0.5889\n",
            "Recall:    0.3557\n",
            "F1-Score:  0.4435\n",
            "MCC:       0.1942\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.82      0.71       201\n",
            "           1       0.59      0.36      0.44       149\n",
            "\n",
            "    accuracy                           0.62       350\n",
            "   macro avg       0.61      0.59      0.58       350\n",
            "weighted avg       0.61      0.62      0.60       350\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definition of models\n",
        "models = {\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('lr', LogisticRegression(C=1.0, solver='liblinear'))\n",
        "    ]),\n",
        "\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        max_depth=5,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=5,\n",
        "        n_estimators= 50,\n",
        "        max_features=0.8,\n",
        "        max_samples= 1.0,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"SVM\": Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', svm.SVC(C=0.1, class_weight= \"balanced\", kernel='rbf', gamma= 0.01, probability=True))\n",
        "    ]),\n",
        "\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=150,\n",
        "        learning_rate=0.01,\n",
        "        max_depth=5,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree = 1.0,\n",
        "        reg_lambda = 10,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"Gradient Boosting (GBM)\": GradientBoostingClassifier(\n",
        "        max_depth=4,\n",
        "        learning_rate= 0.1387,\n",
        "        subsample=0.623,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"LightGBM\": LGBMClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1387,\n",
        "        num_leaves=42,\n",
        "        min_child_samples=57,\n",
        "        subsample=0.623,\n",
        "        colsample_bytree=0.634,\n",
        "        reg_lambda=2.89,\n",
        "        max_depth=-4,\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    ),\n",
        "    \"CatBoost\": CatBoostClassifier(\n",
        "        depth=10,\n",
        "        l2_leaf_reg=9,\n",
        "        learning_rate=0.03,\n",
        "        verbose=False\n",
        "    )\n",
        "}\n",
        "\n",
        "# Loop over all models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    trained_model = train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name=name)\n",
        "    results[name] = trained_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pUtB8V37u3f"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "amkU6wsA7wYV"
      },
      "outputs": [],
      "source": [
        "# Group 1\n",
        "estimators_all = [\n",
        "    ('lr', models['Logistic Regression']),\n",
        "    ('rf', models['Random Forest']),\n",
        "    ('svm', models['SVM']),\n",
        "    ('xgb', models['XGBoost']),\n",
        "    ('gbm', models['Gradient Boosting (GBM)'])\n",
        "]\n",
        "\n",
        "# Group 2\n",
        "estimators_subset = [\n",
        "    ('lr', models['Logistic Regression']),\n",
        "    ('svm', models['SVM']),\n",
        "    ('lgbm', models['LightGBM'],)\n",
        "]\n",
        "\n",
        "estimators_all_new = [\n",
        "    ('lr', models['Logistic Regression']),\n",
        "    ('rf', models['Random Forest']),\n",
        "    ('svm', models['SVM']),\n",
        "    ('xgb', models['XGBoost']),\n",
        "    ('gbm', models['Gradient Boosting (GBM)']),\n",
        "    ('cat', models['CatBoost'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3qSLiuJS70br"
      },
      "outputs": [],
      "source": [
        "# Stacking\n",
        "stack_all = StackingClassifier(\n",
        "    estimators=estimators_all,\n",
        "    final_estimator= LogisticRegression(),\n",
        "    #final_estimator = svm.SVC(C=0.1, class_weight= \"balanced\", kernel='rbf', gamma= 0.01, probability=True),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Voting\n",
        "vote_all = VotingClassifier(\n",
        "    estimators=estimators_all,\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "\n",
        "# --- Szenario 2: Subset (LR, SVM, LightGBM) ---\n",
        "\n",
        "# Stacking\n",
        "stack_subset = StackingClassifier(\n",
        "    estimators=estimators_subset,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    #final_estimator = svm.SVC(C=0.1, class_weight= \"balanced\", kernel='rbf', gamma= 0.01, probability=True),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Voting\n",
        "vote_subset = VotingClassifier(\n",
        "    estimators=estimators_subset,\n",
        "    voting='hard'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "5unNZ1rIsakp"
      },
      "outputs": [],
      "source": [
        "# Option 3: All+new\n",
        "stack_all_new = StackingClassifier(\n",
        "    estimators=estimators_all_new,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    #final_estimator = svm.SVC(C=0.1, class_weight= \"balanced\", kernel='rbf', gamma= 0.01, probability=True),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Voting\n",
        "vote_all_new = VotingClassifier(\n",
        "    estimators=estimators_all_new,\n",
        "    voting='hard'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "rxv8-iKP8dm8"
      },
      "outputs": [],
      "source": [
        "ensemble_models = {\n",
        "    \"Stacking (All)\": stack_all,\n",
        "    \"Voting (All)\": vote_all,\n",
        "    \"Stacking (Subset)\": stack_subset,\n",
        "    \"Voting (Subset)\": vote_subset,\n",
        "    \"Stacking (All+new)\": stack_all_new,\n",
        "    \"Voting (All+new)\": vote_all_new\n",
        "}\n",
        "\n",
        "models.update(ensemble_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MUyypPc8kZS"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": true,
        "id": "2Dt6mW2A8BeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0244f74d-d1bd-4754-c4df-96003f422ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training of models...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                            0              1       2        3   \\\n",
              "Model      Logistic Regression  Random Forest     SVM  XGBoost   \n",
              "Accuracy                  0.62         0.6229  0.6057   0.6543   \n",
              "Precision               0.5755         0.6049  0.5311   0.7121   \n",
              "Recall                  0.4094         0.3289  0.6309   0.3154   \n",
              "F1-Score                0.4784         0.4261  0.5767   0.4372   \n",
              "MCC                     0.1996         0.1989  0.2155   0.2792   \n",
              "\n",
              "                                4         5         6               7   \\\n",
              "Model      Gradient Boosting (GBM)  LightGBM  CatBoost  Stacking (All)   \n",
              "Accuracy                      0.58    0.6114      0.62          0.5857   \n",
              "Precision                   0.5085    0.5512    0.5889           0.625   \n",
              "Recall                      0.4027    0.4698    0.3557          0.0671   \n",
              "F1-Score                    0.4494    0.5072    0.4435          0.1212   \n",
              "MCC                         0.1194    0.1915    0.1942          0.0882   \n",
              "\n",
              "                     8                  9                10  \\\n",
              "Model      Voting (All)  Stacking (Subset)  Voting (Subset)   \n",
              "Accuracy         0.6371             0.5886           0.6514   \n",
              "Precision        0.6196             0.8571           0.5985   \n",
              "Recall           0.3826             0.0403           0.5503   \n",
              "F1-Score          0.473             0.0769           0.5734   \n",
              "MCC              0.2341             0.1246           0.2803   \n",
              "\n",
              "                           11                12  \n",
              "Model      Stacking (All+new)  Voting (All+new)  \n",
              "Accuracy               0.5971            0.6314  \n",
              "Precision                 0.7            0.6282  \n",
              "Recall                  0.094            0.3289  \n",
              "F1-Score               0.1657            0.4317  \n",
              "MCC                    0.1366            0.2193  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d607d08-a557-4e26-a03f-e91d73b12927\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>SVM</td>\n",
              "      <td>XGBoost</td>\n",
              "      <td>Gradient Boosting (GBM)</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>Stacking (All)</td>\n",
              "      <td>Voting (All)</td>\n",
              "      <td>Stacking (Subset)</td>\n",
              "      <td>Voting (Subset)</td>\n",
              "      <td>Stacking (All+new)</td>\n",
              "      <td>Voting (All+new)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.6229</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>0.6543</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.6114</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.5857</td>\n",
              "      <td>0.6371</td>\n",
              "      <td>0.5886</td>\n",
              "      <td>0.6514</td>\n",
              "      <td>0.5971</td>\n",
              "      <td>0.6314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.5755</td>\n",
              "      <td>0.6049</td>\n",
              "      <td>0.5311</td>\n",
              "      <td>0.7121</td>\n",
              "      <td>0.5085</td>\n",
              "      <td>0.5512</td>\n",
              "      <td>0.5889</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.6196</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.5985</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.4094</td>\n",
              "      <td>0.3289</td>\n",
              "      <td>0.6309</td>\n",
              "      <td>0.3154</td>\n",
              "      <td>0.4027</td>\n",
              "      <td>0.4698</td>\n",
              "      <td>0.3557</td>\n",
              "      <td>0.0671</td>\n",
              "      <td>0.3826</td>\n",
              "      <td>0.0403</td>\n",
              "      <td>0.5503</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.3289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1-Score</th>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.4261</td>\n",
              "      <td>0.5767</td>\n",
              "      <td>0.4372</td>\n",
              "      <td>0.4494</td>\n",
              "      <td>0.5072</td>\n",
              "      <td>0.4435</td>\n",
              "      <td>0.1212</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.0769</td>\n",
              "      <td>0.5734</td>\n",
              "      <td>0.1657</td>\n",
              "      <td>0.4317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MCC</th>\n",
              "      <td>0.1996</td>\n",
              "      <td>0.1989</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.2792</td>\n",
              "      <td>0.1194</td>\n",
              "      <td>0.1915</td>\n",
              "      <td>0.1942</td>\n",
              "      <td>0.0882</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1246</td>\n",
              "      <td>0.2803</td>\n",
              "      <td>0.1366</td>\n",
              "      <td>0.2193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d607d08-a557-4e26-a03f-e91d73b12927')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d607d08-a557-4e26-a03f-e91d73b12927 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d607d08-a557-4e26-a03f-e91d73b12927');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-704be057-0ddd-4a8f-8874-74018c29e26d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-704be057-0ddd-4a8f-8874-74018c29e26d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-704be057-0ddd-4a8f-8874-74018c29e26d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_036dccac-32ba-41f8-9d84-c82838b72ee1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('transposed')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_036dccac-32ba-41f8-9d84-c82838b72ee1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('transposed');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "transposed",
              "summary": "{\n  \"name\": \"transposed\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Logistic Regression\",\n          0.62,\n          0.1996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Random Forest\",\n          0.6229,\n          0.1989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"SVM\",\n          0.6057,\n          0.2155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"XGBoost\",\n          0.6543,\n          0.2792\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Gradient Boosting (GBM)\",\n          0.58,\n          0.1194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"LightGBM\",\n          0.6114,\n          0.1915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"CatBoost\",\n          0.62,\n          0.1942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Stacking (All)\",\n          0.5857,\n          0.0882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Voting (All)\",\n          0.6371,\n          0.2341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Stacking (Subset)\",\n          0.5886,\n          0.1246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Voting (Subset)\",\n          0.6514,\n          0.2803\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Stacking (All+new)\",\n          0.5971,\n          0.1366\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Voting (All+new)\",\n          0.6314,\n          0.2193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "\n",
        "# 1. empty list for results\n",
        "results = []\n",
        "\n",
        "print(\"Start training of models...\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Training\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # prediction\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, pos_label=1)\n",
        "    rec = recall_score(y_test, y_pred, pos_label=1)\n",
        "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    # save results\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1-Score\": f1,\n",
        "        \"MCC\": mcc\n",
        "    })\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "df_results = df_results.round(4)\n",
        "\n",
        "transposed = df_results.transpose()\n",
        "transposed.to_csv(\"results_wetter_only_start.csv\", index=True)\n",
        "\n",
        "# show table\n",
        "display(transposed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}